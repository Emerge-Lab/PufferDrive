{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PufferDrive","text":"<p>PufferDrive is a high-throughput autonomous driving simulator built on PufferLib. It pairs a fast vectorized simulator with data conversion and benchmarking scripts so you can train and evaluate agents with minimal setup.</p>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>Multi-agent drive environment with batched stepping for speed.</li> <li>Scripts to convert Waymo Open Motion Dataset JSON into lightweight binaries.</li> <li>Benchmarks for distributional realism and human compatibility.</li> <li>Raylib-based visualizer for local or headless render/export.</li> </ul>"},{"location":"#quick-start","title":"Quick start","text":"<ul> <li>Follow Getting Started to install, build the C extensions, and run <code>puffer train puffer_drive</code>.</li> <li>Consult Simulator for how actions/observations, rewards, and <code>.ini</code> settings map to the underlying C environment and Torch policy.</li> <li>Prepare drive map binaries with the steps in Data.</li> <li>Evaluate a policy with the commands in Evaluation and preview runs with the Visualizer.</li> </ul>"},{"location":"#repository-layout","title":"Repository layout","text":"<ul> <li><code>pufferlib/ocean/drive</code>: Drive environment implementation and map processing utilities.</li> <li><code>resources/drive/binaries</code>: Expected location for compiled map binaries (outputs of the data conversion step).</li> <li><code>scripts/build_ocean.sh</code>: Helper for building the Raylib visualizer and related binaries.</li> <li><code>examples</code>, <code>tests</code>, <code>experiments</code>: Reference usage, checks, and research scripts that pair with the docs pages.</li> </ul>"},{"location":"data/","title":"Data","text":"<p>PufferDrive consumes map binaries generated from the Waymo Open Motion Dataset (WOMD) JSON files. This page covers where to obtain data and how to convert it into the binary format expected by the simulator.</p>"},{"location":"data/#download-options","title":"Download options","text":"<ul> <li>Mini dataset: GPUDrive_mini with ~1k training files for quick experiments.</li> <li>Full dataset: GPUDrive with ~100k scenes for large-scale training.</li> <li>Additional compatible sources: ScenarioMax exports JSON in the same format.</li> </ul> <p>Place raw JSON files under <code>data/processed/training</code> (default location read by the conversion script).</p>"},{"location":"data/#convert-json-to-map-binaries","title":"Convert JSON to map binaries","text":"<p>The conversion script writes compact <code>.bin</code> maps to <code>resources/drive/binaries</code>:</p> <pre><code>python pufferlib/ocean/drive/drive.py\n</code></pre> <p>Notes: - The script iterates every JSON file in <code>data/processed/training</code> and emits <code>map_XXX.bin</code> files. - <code>resources/drive/binaries/map_000.bin</code> is required at runtime; keep it in version control for tests. - If you want to point at a different dataset location or limit the number of maps, adjust <code>process_all_maps</code> in <code>pufferlib/ocean/drive/drive.py</code> before running.</p>"},{"location":"data/#map-binary-format-reference","title":"Map binary format reference","text":"<p>The simulator reads the compact binary layout produced by <code>save_map_binary</code> in <code>pufferlib/ocean/drive/drive.py</code> and parsed by <code>load_map_binary</code> in <code>pufferlib/ocean/drive/drive.h</code>:</p> <ul> <li>Header: <code>sdc_track_index</code> (int), <code>num_tracks_to_predict</code> (int) followed by that many <code>track_index</code> ints, <code>num_objects</code> (int), <code>num_roads</code> (int).</li> <li>Objects (vehicles/pedestrians/cyclists): For each object, the writer stores <code>scenario_id</code> (<code>unique_map_id</code> passed to <code>load_map</code>), <code>type</code> (<code>1</code> vehicle, <code>2</code> pedestrian, <code>3</code> cyclist), <code>id</code>, <code>array_size</code> (<code>TRAJECTORY_LENGTH = 91</code>), positions <code>x/y/z[91]</code>, velocities <code>vx/vy/vz[91]</code>, <code>heading[91]</code>, <code>valid[91]</code>, and scalars <code>width/length/height</code>, <code>goalPosition (x, y, z)</code>, <code>mark_as_expert</code> (int). Missing trajectory entries are zero-padded by the converter.</li> <li>Road elements: Each road entry stores <code>scenario_id</code>, a remapped <code>type</code> (<code>4</code> lane, <code>5</code> road line, <code>6</code> road edge, <code>7</code> stop sign, <code>8</code> crosswalk, <code>9</code> speed bump, <code>10</code> driveway), <code>id</code>, <code>array_size</code> (#points), then <code>x/y/z</code> arrays of that length and scalars <code>width/length/height</code>, <code>goalPosition</code>, <code>mark_as_expert</code>. <code>save_map_binary</code> also simplifies long polylines (<code>len(geometry) &gt; 10</code> and <code>type &lt;= 16</code>) with a 0.1 area threshold to keep files small.</li> <li>Control hints: <code>tracks_to_predict</code> and <code>mark_as_expert</code> influence which agents are controllable (<code>control_mode</code> in the simulator) versus replayed as experts or static actors (<code>set_active_agents</code> in <code>drive.h</code>).</li> </ul> <p>Refer to Simulator for how the binaries are consumed during resets, observation construction, and reward logging.</p>"},{"location":"data/#verifying-data-availability","title":"Verifying data availability","text":"<ul> <li>After conversion, <code>ls resources/drive/binaries | head</code> should show numbered <code>.bin</code> files.</li> <li>If you see <code>Required directory resources/drive/binaries/map_000.bin not found</code> during training, rerun the conversion or check paths.</li> <li>To inspect the binary output, convert a single JSON file with <code>load_map(&lt;json&gt;, &lt;id&gt;, &lt;output_path&gt;)</code> inside <code>drive.py</code>.</li> </ul>"},{"location":"data/#waymo-map-editor","title":"Waymo map editor","text":"<p>See WOMD Editor for a browser-based workflow to inspect, edit, and export Waymo/ScenarioMax JSON into the <code>.bin</code> format consumed by the simulator.</p>"},{"location":"evaluation/","title":"Evaluation","text":"<p>Benchmarks are provided to measure how closely agents match real-world driving behavior and how well they pair with human trajectories.</p>"},{"location":"evaluation/#wosac-distributional-realism","title":"WOSAC distributional realism","text":"<p>Evaluate how realistic your policy behaves compared to the Waymo Open Sim Agents Challenge (WOSAC):</p> <pre><code>puffer eval puffer_drive --eval.wosac-realism-eval True\n</code></pre> <p>Add <code>--load-model-path &lt;path_to_checkpoint&gt;.pt</code> to score a trained policy instead of a random baseline.</p>"},{"location":"evaluation/#human-compatibility","title":"Human-compatibility","text":"<p>Test how a policy coexists with human-controlled agents:</p> <pre><code>puffer eval puffer_drive --eval.human-replay-eval True --load-model-path &lt;path_to_checkpoint&gt;.pt\n</code></pre> <p>During this evaluation the self-driving car (SDC) is controlled by your policy while other agents replay log data.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This page walks through installing PufferDrive from source, building the native extensions, and running a first training job.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+ with a virtual environment manager (<code>uv</code>, <code>venv</code>, or <code>conda</code>).</li> <li>A C/C++ toolchain for building the bundled extensions (GCC/Clang + make).</li> <li>PyTorch preinstalled if you want to skip build isolation during editable installs.</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>Clone and set up an isolated environment:</p> <pre><code>git clone https://github.com/Emerge-Lab/PufferDrive.git\ncd PufferDrive\nuv venv .venv &amp;&amp; source .venv/bin/activate  # or python -m venv .venv\nuv pip install -e .  # or pip install -e .\n</code></pre> <p>Build the C extensions in place:</p> <pre><code>python setup.py build_ext --inplace --force\n</code></pre>"},{"location":"getting-started/#when-to-rebuild-the-extension","title":"When to rebuild the extension","text":"<ul> <li>Re-run <code>python setup.py build_ext --inplace --force</code> after changing any C/Raylib sources in <code>pufferlib/ocean/drive</code> (e.g., <code>drive.c</code>, <code>drive.h</code>, <code>binding.c</code>, <code>visualize.c</code>) or after pulling upstream changes that touch those files. This regenerates the <code>binding.cpython-*.so</code> used by <code>Drive</code>.</li> <li>Pure Python edits (training scripts, docs, data utilities) do not require a rebuild; just restart your Python process.</li> </ul>"},{"location":"getting-started/#verify-the-setup","title":"Verify the setup","text":"<p>Launch a quick training run to confirm the environment, data, and bindings are wired up correctly:</p> <pre><code>puffer train puffer_drive\n</code></pre> <p>If map binaries are missing, follow the steps in Data to generate them before training. See Visualizer for rendering runs and Evaluation for benchmark commands.</p>"},{"location":"getting-started/#logging-with-weights-biases","title":"Logging with Weights &amp; Biases","text":"<p>Enable W&amp;B logging with the built-in CLI flags (the package is already a dependency in <code>setup.py</code>):</p> <pre><code>puffer train puffer_drive --wandb --wandb-project pufferdrive --wandb-group local-dev\n</code></pre> <ul> <li>Add <code>--wandb</code> to turn on logging; <code>--wandb-project</code> and <code>--wandb-group</code> set the destination in W&amp;B.</li> <li>Checkpoint uploads and evaluation helpers (<code>pufferlib/utils.py</code>) will log WOSAC/human-replay metrics and rendered videos when W&amp;B is enabled.</li> </ul>"},{"location":"simulator/","title":"Simulator Guide","text":"<p>Deep dive into how the Drive environment is wired, what it expects as inputs, and how observations/actions/configs are shaped. The environment entrypoint is <code>pufferlib/ocean/drive/drive.py</code>, which wraps the C core in <code>pufferlib/ocean/drive/drive.h</code> via <code>binding.c</code>.</p>"},{"location":"simulator/#runtime-inputs-and-lifecycle","title":"Runtime inputs and lifecycle","text":"<ul> <li>Map binaries: The environment expects <code>resources/drive/binaries/map_000.bin</code> to exist and <code>num_maps</code> to be no larger than the available <code>.bin</code> files. During vectorized setup, <code>binding.shared</code> samples maps until it accumulates at least <code>num_agents</code> controllable entities, skipping maps with no valid agents (<code>set_active_agents</code> in <code>drive.h</code>).</li> <li>Episode length: Default <code>scenario_length = 91</code> to match the Waymo logs (trajectory data is 91 steps), but you can set <code>env.scenario_length</code> (CLI or <code>.ini</code>) to any positive value. Metrics are logged and <code>c_reset</code> is called when <code>timestep == scenario_length</code>.</li> <li>Resampling maps: Python-side <code>Drive.step</code> reinitializes the vectorized environments every <code>resample_frequency</code> steps (default <code>910</code>, ~10 episodes) with fresh map IDs and seeds.</li> <li>Initialization controls:</li> <li><code>init_steps</code> starts agents from a later timestep in the logged trajectory.</li> <li><code>init_mode</code> (<code>create_all_valid</code> vs <code>create_only_controlled</code>) decides which logged actors are instantiated at reset.</li> <li><code>control_mode</code> (<code>control_vehicles</code>, <code>control_agents</code>, <code>control_tracks_to_predict</code>, <code>control_sdc_only</code>) selects which instantiated actors are policy-controlled. Non-controlled actors can still appear as static or expert replay agents.</li> <li><code>goal_behavior</code> chooses what happens on goal reach (<code>0</code> respawn at start pose, <code>1</code> sample new lane-following goals via the lane topology graph, <code>2</code> stop in place). <code>goal_radius</code> sets the completion threshold in meters.</li> </ul> <p>See Data for how to produce the <code>.bin</code> inputs, including the binary layout.</p>"},{"location":"simulator/#actions-and-dynamics","title":"Actions and dynamics","text":"<ul> <li>Action types (<code>env.action_type</code>):</li> <li><code>discrete</code> (default): classic dynamics use a single <code>MultiDiscrete([7*13])</code> index decoded into acceleration (<code>ACCELERATION_VALUES</code>) and steering (<code>STEERING_VALUES</code>); jerk dynamics use <code>MultiDiscrete([4, 3])</code> over <code>JERK_LONG</code>/<code>JERK_LAT</code>.</li> <li><code>continuous</code>: a 2-D Box in <code>[-1, 1]</code>. Classic scales to the max accel/steer magnitudes used in the discrete table. Jerk scales asymmetrically: negative values reach up to <code>-15 m/s^3</code> braking, positives up to <code>4 m/s^3</code> acceleration, lateral jerk up to <code>\u00b14 m/s^3</code>.</li> <li>Dynamics models (<code>env.dynamics_model</code>):</li> <li><code>classic</code>: bicycle model integrating accel/steer with <code>dt</code> (default <code>0.1</code>).</li> <li><code>jerk</code>: integrates longitudinal/lateral jerk into accel, then into velocity/pose with steering limited to <code>\u00b10.55 rad</code>. Speeds are clipped to <code>[0, 20] m/s</code>.</li> </ul>"},{"location":"simulator/#observation-space","title":"Observation space","text":"<p>Shape is <code>ego_features + 63 * 7 + 200 * 7</code> = <code>1848</code> for classic dynamics (<code>ego_features = 7</code>) or <code>1851</code> for jerk dynamics (<code>ego_features = 10</code>). Computed in <code>compute_observations</code> (<code>drive.h</code>):</p> <ul> <li>Ego block (classic):</li> <li>Goal position in ego frame (x, y) scaled by <code>0.005</code> (~200 m range to 1.0)</li> <li>Ego speed / <code>MAX_SPEED</code> (100 m/s)</li> <li>Width / <code>MAX_VEH_WIDTH</code> (15 m)</li> <li>Length / <code>MAX_VEH_LEN</code> (30 m)</li> <li>Collision flag (1 if the agent collided this step)</li> <li>Respawn flag (1 if the agent was respawned this episode)</li> <li>Ego block additions (jerk only):</li> <li>Steering angle / \u03c0</li> <li>Longitudinal acceleration normalized to <code>[-15, 4]</code></li> <li>Lateral acceleration normalized to <code>[-4, 4]</code></li> <li>Respawn flag (index 9)</li> <li>Partner blocks: Up to 63 other agents (active first, then static experts) within 50 m. Each uses 7 values: relative (x, y) in ego frame scaled by <code>0.02</code>, width/length normalized as above, relative heading encoded as <code>(cos \u0394\u03b8, sin \u0394\u03b8)</code>, and speed / <code>MAX_SPEED</code>. Zero-padded when fewer neighbors are present or when agents are in respawn.</li> <li>Road blocks: Up to 200 nearby road segments pulled from a precomputed grid (<code>vision_range = 21</code>). Each entry stores relative midpoint (x, y) scaled by <code>0.02</code>, segment length / <code>MAX_ROAD_SEGMENT_LENGTH</code> (100 m), width / <code>MAX_ROAD_SCALE</code> (100), <code>(cos, sin)</code> of the segment direction in ego frame, and a type ID (<code>ROAD_LANE</code>..<code>DRIVEWAY</code> stored as <code>0..6</code>). Remaining slots are zero-padded.</li> </ul>"},{"location":"simulator/#rewards-termination-and-metrics","title":"Rewards, termination, and metrics","text":"<ul> <li>Per-step rewards (<code>c_step</code>):</li> <li>Collision with another actor: <code>reward_vehicle_collision</code> (default <code>-0.5</code>)</li> <li>Off-road (road-edge intersection): <code>reward_offroad_collision</code> (default <code>-0.2</code>)</li> <li>Goal reached: <code>reward_goal</code> (default <code>1.0</code>) or <code>reward_goal_post_respawn</code> after a respawn</li> <li>Optional ADE shaping: <code>reward_ade * avg_displacement_error</code>, where ADE is accumulated in <code>compute_agent_metrics</code></li> <li>Termination: No early truncation; episodes roll to <code>scenario_length</code> steps. If <code>goal_behavior</code> is respawn, <code>respawn_agent</code> resets the pose and marks <code>respawn_timestep</code> so the respawn flag shows up in observations.</li> <li>Logged metrics (<code>add_log</code> aggregates over all active agents across envs):</li> <li><code>score</code>: reached goal without collision/off-road</li> <li><code>collision_rate</code> / <code>offroad_rate</code>: fraction of agents with \u22651 event in the episode</li> <li><code>avg_collisions_per_agent</code> / <code>avg_offroad_per_agent</code>: counts per agent, capturing repeated events</li> <li><code>completion_rate</code>: reached goal (even if collided/off-road); <code>dnf_rate</code>: clean but never reached goal</li> <li><code>lane_alignment_rate</code>, <code>avg_displacement_error</code>, <code>num_goals_reached</code>, plus counts of active/static/expert agents</li> </ul> <p><code>collision_behavior</code>, <code>offroad_behavior</code>, <code>reward_vehicle_collision_post_respawn</code>, and <code>spawn_immunity_timer</code> are parsed from the INI but currently unused in the stepping logic.</p>"},{"location":"simulator/#configuration-files-ini","title":"Configuration files (<code>.ini</code>)","text":"<p><code>pufferlib/config/default.ini</code> supplies global defaults. Environment-specific overrides live in <code>pufferlib/config/ocean/drive.ini</code> and are loaded first when you run <code>puffer train puffer_drive</code>; CLI flags (e.g., <code>--env.num-maps 128</code>) override both.</p> <p>Key sections in <code>pufferlib/config/ocean/drive.ini</code>: - [env]: Simulator knobs: <code>num_agents</code> (policy slots, C core cap 64), <code>num_maps</code>, <code>scenario_length</code>, <code>resample_frequency</code>, <code>action_type</code>, <code>dynamics_model</code>, rewards, <code>goal_radius</code>, <code>goal_behavior</code>, <code>init_steps</code>, <code>init_mode</code>, <code>control_mode</code>; rendering toggles <code>render</code>, <code>render_interval</code>, <code>obs_only</code>, <code>show_grid</code>, <code>show_lasers</code>, <code>show_human_logs</code>, <code>render_map</code>. - [vec]: Vectorization sizing (<code>num_envs</code>, <code>num_workers</code>, <code>batch_size</code>; backend defaults to multiprocessing). - [policy]/[rnn]: Model widths for the Torch policy (<code>input_size</code>, <code>hidden_size</code>) and optional LSTM wrapper. - [train]: PPO-style hyperparameters (timesteps, learning rate, clipping, batch/minibatch, BPTT horizon, optimizer choice) merged with any unspecified defaults from <code>pufferlib/config/default.ini</code>. - [eval]: WOSAC/human-replay switches and sizing (<code>eval.wosac_*</code>, <code>eval.human_replay_*</code>) mapped directly to the <code>Drive</code> kwargs in evaluation subprocesses.</p>"},{"location":"simulator/#model-overview","title":"Model overview","text":"<p>Defined in <code>pufferlib/ocean/torch.py:Drive</code>: - Three MLP encoders (ego, partners, roads) with LayerNorm. Partner and road encodings are max-pooled across instances. - Concatenated embedding \u2192 GELU \u2192 linear to <code>hidden_size</code>, then split into actor/value heads. - Discrete actions are emitted as logits per dimension (<code>MultiDiscrete</code>), continuous actions as Gaussian parameters (<code>softplus</code> std). Value head is a single linear output. - <code>Recurrent = pufferlib.models.LSTMWrapper</code> can wrap the policy using the <code>rnn</code> config entries; otherwise the policy is feed-forward.</p>"},{"location":"simulator/#drive-source-files-what-lives-where","title":"Drive source files (what lives where)","text":"<ul> <li><code>pufferlib/ocean/drive/drive.py</code>: Python Gymnasium-style wrapper that sets up buffers, validates map availability, seeds the C core via <code>binding.env_init</code>, and handles map resampling.</li> <li><code>pufferlib/ocean/drive/drive.h</code>: Main C implementation of stepping, observations, rewards/metrics, grid map, lane graph, and collision checking.</li> <li><code>pufferlib/ocean/drive/binding.c</code>: Python C-extension glue that exposes <code>Drive</code> to Python, handles shared buffer setup, logging, and reading the <code>.ini</code> config.</li> <li><code>pufferlib/ocean/drive/visualize.c</code>: Raylib-based renderer used by the <code>visualize</code> binary and training video exports.</li> <li><code>pufferlib/ocean/drive/drive.c</code>: Small C demo/perf harness and network parity test runner for the C policy head.</li> <li><code>pufferlib/ocean/drive/drivenet.h</code>: Lightweight C inference network used by the visualizer/demo to mirror the Torch policy outputs.</li> </ul>"},{"location":"visualizer/","title":"Visualizer","text":"<p>PufferDrive ships a Raylib-based visualizer for replaying scenes, exporting videos, and debugging policies.</p>"},{"location":"visualizer/#dependencies","title":"Dependencies","text":"<p>Install the minimal system packages for headless render/export:</p> <pre><code>sudo apt update\nsudo apt install ffmpeg xvfb\n</code></pre> <p>On environments without sudo, install them into your conda/venv:</p> <pre><code>conda install -c conda-forge xorg-x11-server-xvfb-cos6-x86_64 ffmpeg\n</code></pre>"},{"location":"visualizer/#build","title":"Build","text":"<p>Compile the visualizer binary from the repo root:</p> <pre><code>bash scripts/build_ocean.sh visualize local\n</code></pre> <p>If you need to force a rebuild, remove the cached binary first (<code>rm ./visualize</code>).</p>"},{"location":"visualizer/#run-headless","title":"Run headless","text":"<p>Launch the visualizer with a virtual display and export an <code>.mp4</code>:</p> <pre><code>xvfb-run -s \"-screen 0 1280x720x24\" ./visualize\n</code></pre> <p>Adjust the screen size and color depth as needed. The <code>xvfb-run</code> wrapper allows Raylib to render without an attached display, which is convenient for servers and CI jobs.</p>"},{"location":"womd-editor/","title":"WOMD Editor","text":"<p>A browser-based playground for inspecting and editing Waymo Open Motion Dataset (WOMD) scenes. The tool runs fully client-side at https://womd-editor.vercel.app/ and works directly with the JSON format produced by Waymo/ScenarioMax exports and PufferDrive conversions.</p>"},{"location":"womd-editor/#quick-start","title":"Quick start","text":"<ul> <li>Open https://womd-editor.vercel.app/ in a modern Chromium/Firefox browser.</li> <li>Click Import JSON\u2026 in the left sidebar and drop one or more scenario files (Waymo/ScenarioMax JSON or editor exports).</li> <li>The app stores everything in-memory only; nothing is uploaded to a server.</li> </ul>"},{"location":"womd-editor/#what-you-can-do","title":"What you can do","text":"<ul> <li>Inspect: Top-down canvas with zoom/pan/rotate, agent labels, and a playback timeline with variable speed.</li> <li>Edit trajectories: Select an agent and tweak paths via drag handles, draw a polyline with the Line tool, freehand record a path, or drive the agent with keyboard controls (WASD/arrow keys, Space to brake, Enter to save, Esc to cancel).</li> <li>Edit roads: Switch to Road mode to draw or refine lane/edge/crosswalk geometry, recolor vertices by elevation, and view the lane connectivity overlay when ROAD_LANE/ROAD_LINE data exists.</li> <li>Configure metadata: Rename the scenario, toggle label mode (ID vs. array index), mark agents as experts, and choose which agents belong to <code>tracks_to_predict</code>.</li> <li>Export: Preview changes versus the import baseline, then download either Waymo-style JSON or a compact <code>.bin</code> suitable for PufferDrive\u2019s loader.</li> </ul>"},{"location":"womd-editor/#editing-workflow","title":"Editing workflow","text":"<ol> <li>Load a scene: Import one or multiple JSONs; each appears as a row in the Scenarios list with a quick delete button.</li> <li>Playback: Use the timeline to scrub frames or Space/Arrow keys to play/pause/step. Agent labels and trajectory visibility can be toggled in the editor panel.</li> <li>Trajectory tools (Trajectory mode):</li> <li>Adjust Path: Drag existing vertices/handles on the canvas.</li> <li>Line Tool: Click to lay out a polyline, set per-segment duration (seconds), then Apply Path to rebuild timestamps/velocity.</li> <li>Record Path: Freehand capture a path with the pointer; playback resets to frame 0.</li> <li>Drive Agent: Enter a lightweight driving loop; W/A/S/D or arrow keys steer, Space brakes, Enter saves, Esc cancels. Tunable speed/accel/steer sliders live under \u201cDrive Tune.\u201d</li> <li>Road tools (Road mode):</li> <li>Edit Geometry: Select segments/vertices to move, insert, split, or delete (Shift/Ctrl-click to insert on-canvas; Alt/Cmd-click to delete).</li> <li>Draw Road: Click to add vertices; Enter finishes, Esc cancels. Set the default Z used for new vertices in the right-hand panel.</li> <li>Type &amp; overlays: Tag segments as ROAD_LANE / ROAD_EDGE / ROAD_LINE / CROSSWALK / OTHER. Enable Color by Z to visualize elevation and Lane Graph to see lane entry/exit nodes plus downstream arrows.</li> <li>Export &amp; diff: Hit Export to open a preview modal that summarizes changes (metadata, agents, roads, tracks_to_predict, bounds, frames). Download JSON for round-tripping or <code>.bin</code> for simulator ingestion.</li> </ol>"},{"location":"womd-editor/#using-exports-with-pufferdrive","title":"Using exports with PufferDrive","text":"<ul> <li>JSON exports retain the Waymo layout (<code>objects</code>, <code>roads</code>, <code>tracks_to_predict</code>, <code>tl_states</code>, <code>metadata</code>) and can be converted or re-imported.</li> <li><code>.bin</code> exports match the compact format read by <code>pufferlib/ocean/drive/drive.py</code>; drop them into <code>resources/drive/binaries</code> (e.g., <code>map_000.bin</code>) to test inside the simulator.</li> <li>The editor auto-fills missing headings/speeds and clamps degenerate lanes to keep bounds reasonable; always spot-check via the Export preview before committing.</li> </ul>"},{"location":"womd-editor/#notes","title":"Notes","text":"<ul> <li>The app is currently work-in-progress; there is no persistent storage or backend sync.</li> <li>Large scenes may render slowly on low-power GPUs\u2014hide trajectories or road overlays to keep the canvas responsive.</li> <li>Source lives in the <code>WOMD-Editor/web</code> directory of this repo if you want to run it locally with <code>npm install &amp;&amp; npm run dev</code>.</li> </ul>"}]}